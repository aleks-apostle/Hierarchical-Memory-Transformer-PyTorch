# Table 1 Reproduction: PG-19 Evaluation
# Paper Reference: Table 1 - PG-19 dataset (long books)
# arXiv:2405.06067v3 [cs.CL] 6 Feb 2025

experiment:
  name: "table1_pg19_opt350m"
  paper_reference: "Table 1 - PG-19"
  description: "Reproduce PG-19 results with OPT-350M backbone"
  reproducibility_notes: |
    PG-19 contains long-form books (avg 69K tokens).
    Tests true long-context understanding.
    Metric: Bits-per-Byte (BPB) instead of perplexity.

model:
  backbone: "facebook/opt-350m"
  checkpoint: "checkpoints/hmt_opt350m_pg19_best.pt"
  load_from_checkpoint: true

hmt_config:
  segment_length: 1024  # L
  num_memory_embeddings: 300  # N
  sensory_memory_size: 32  # k
  representation_length: 512  # j = L/2

evaluation:
  dataset: "pg19"
  split: "test"
  batch_size: 1  # Books are very long

  # PG-19 specific
  max_book_length: 100000  # Limit to 100K tokens per book
  sample_books: null  # Use all test books (100 total)

  metrics:
    - bits_per_byte  # Primary metric for PG-19 (Table 1)
    - perplexity  # Also compute PPL
    - loss

  use_memory: true

baselines:
  - name: "vanilla"
    enabled: true
    model_type: "vanilla"
    max_length: 2048
    truncation_strategy: "tail"

  - name: "sliding_window"
    enabled: true
    model_type: "sliding_window"
    window_size: 1024
    stride: 512

output:
  results_dir: "results/paper_reproduction/table1/pg19/"
  save_predictions: false
  save_metrics: true
  generate_plots: true
  plot_formats: ["png", "pdf"]

  export_latex: true
  latex_precision: 3  # BPB typically reported to 3 decimals

reproducibility:
  seed: 42
  deterministic: true
  device: null

# Paper-specific validation
validation:
  paper_bpb: null  # Fill in from paper if available
  tolerance: 0.05
  warn_if_exceeds: true

# PG-19 specific notes
notes: |
  PG-19 requires manual download in some environments.
  See: https://github.com/deepmind/pg19

  The paper uses BPB metric: BPB = loss / log(2)
  Lower BPB = better compression = better language model.
